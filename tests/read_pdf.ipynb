{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Crawl_buffett\n"
     ]
    }
   ],
   "source": [
    "import tabula, camelot, os, time\n",
    "import os, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import requests\n",
    "\n",
    "# warnings.simplefilter(\"ignore\", UserWarning)\n",
    "%cd .."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get table from pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_table(df):\n",
    "    df.loc[-1] = df.columns\n",
    "    df = df.sort_index()\n",
    "    df.columns = np.arange(len(df.columns))\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def find_row_data(df, text):\n",
    "    list_id = np.where((df[0].str.find(text) > 0) == True)[0]\n",
    "    if len(list_id) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return list_id[0] \n",
    "    \n",
    "def get_vol_table_tabula(file_path, \n",
    "                         key_word = \"期末発行済株式数(自己株式を含む)\", \n",
    "                         type_get = 'volume'):\n",
    "    if 'https' in file_path:\n",
    "        tables = tabula.read_pdf(file_path, pages=\"all\", multiple_tables=True, silent=True, stream=True)\n",
    "    else:\n",
    "        tables = tabula.read_pdf(file_path, pages=\"all\", multiple_tables=True, silent=True)\n",
    "    for table in range(len(tables)):\n",
    "        df = pd.DataFrame(tables[table])\n",
    "        if type_get == 'volume':\n",
    "            df = convert_table(df)\n",
    "            row_id = find_row_data(df, key_word)\n",
    "            if row_id is not None and len(df.columns) < 10 and len(df[0][0]) < 100:\n",
    "                return df\n",
    "        else:\n",
    "            print(df)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tabula' has no attribute 'read_pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m path_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtests/Data/1301/PDF/2020_Q4_決算短信(2021_5_14).pdf\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m tables \u001b[39m=\u001b[39m tabula\u001b[39m.\u001b[39;49mread_pdf(path_file, pages\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m, multiple_tables\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tabula' has no attribute 'read_pdf'"
     ]
    }
   ],
   "source": [
    "path_file = 'tests/Data/1301/PDF/2020_Q4_決算短信(2021_5_14).pdf'\n",
    "tables = tabula.read_pdf(path_file, pages=\"all\", multiple_tables=True, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(tables[\u001b[39m4\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tables' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(tables[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pd\u001b[39m.\u001b[39mDataFrame(tables[\u001b[39m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tables' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     df[year]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m year\n\u001b[0;32m     13\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[1;32m---> 15\u001b[0m get_dividend_table(tables)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tables' is not defined"
     ]
    }
   ],
   "source": [
    "def get_dividend_table(tables, \n",
    "                       year = 'Any'):\n",
    "    df = pd.DataFrame(tables[4])\n",
    "    # print(df)\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "    df.columns = np.arange(len(df.columns))\n",
    "    df.drop(columns=df.columns[5:], inplace=True)\n",
    "    df.dropna(axis=0, how='all', inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.drop([0, 1, 2, 4], inplace=True)\n",
    "    df.columns = [year, 'Q1', 'Q2', 'Q3', 'Q4']\n",
    "    df[year].iloc[0] = year\n",
    "    return df\n",
    "\n",
    "get_dividend_table(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dividend_table_from_pdf(id_company, year, \n",
    "                                quy = 'Q4', \n",
    "                                path_save = ''):\n",
    "    for file in os.listdir(path_save + f'Data/{id_company}/PDF'):\n",
    "        if file.startswith(f'{year}_{quy}') and '(訂正)' not in file:\n",
    "            file_name = file\n",
    "            path_of_file = path_save + f'Data/{id_company}/PDF/{file_name}'\n",
    "            tables = tabula.read_pdf(path_of_file, pages=\"all\", multiple_tables=True, silent=True)\n",
    "            try:\n",
    "                df = get_dividend_table(tables, year)\n",
    "                if len(df.index) == 1:\n",
    "                    return df.reset_index(drop=True)\n",
    "            except:\n",
    "                pass\n",
    "    return pd.DataFrame({year: year, 'Q1':'B', 'Q2':'B', 'Q3':'B', 'Q4':'B'}, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_dividend_table_from_pdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m             df_dividend\u001b[39m.\u001b[39mloc[(\u001b[39mlen\u001b[39m(df_dividend))] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(df_dividend_year\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m])\n\u001b[0;32m     13\u001b[0m     \u001b[39mreturn\u001b[39;00m df_dividend\n\u001b[1;32m---> 15\u001b[0m df_dividend \u001b[39m=\u001b[39m get_dividend(\u001b[39m1301\u001b[39;49m, path_save\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtests/\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     16\u001b[0m \u001b[39m# df_dividend.to_csv('tests/Data/1301/docs/dividend.csv', index=False)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m, in \u001b[0;36mget_dividend\u001b[1;34m(id_company, path_save, return_df, save_file)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mindex:\n\u001b[0;32m      9\u001b[0m     year \u001b[39m=\u001b[39m df[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mYear\u001b[39m\u001b[39m'\u001b[39m][\u001b[39mid\u001b[39m]\n\u001b[1;32m---> 10\u001b[0m     df_dividend_year \u001b[39m=\u001b[39m get_dividend_table_from_pdf(id_company, year, quy, path_save)\n\u001b[0;32m     11\u001b[0m     \u001b[39m# print(df_dividend_year.iloc[0])\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     df_dividend\u001b[39m.\u001b[39mloc[(\u001b[39mlen\u001b[39m(df_dividend))] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(df_dividend_year\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_dividend_table_from_pdf' is not defined"
     ]
    }
   ],
   "source": [
    "def get_dividend(id_company, \n",
    "               path_save = '', \n",
    "               return_df = False, \n",
    "               save_file = True):\n",
    "    df = pd.read_csv(path_save + f'Data/{id_company}/docs/link.csv')\n",
    "    df_dividend = pd.DataFrame(columns=['Year', 'Q1', 'Q2', 'Q3', 'Q4'])\n",
    "    for quy in ['Q4']:\n",
    "        for id in df.index:\n",
    "            year = df[f'Year'][id]\n",
    "            df_dividend_year = get_dividend_table_from_pdf(id_company, year, quy, path_save)\n",
    "            # print(df_dividend_year.iloc[0])\n",
    "            df_dividend.loc[(len(df_dividend))] = list(df_dividend_year.iloc[0])\n",
    "    return df_dividend\n",
    "\n",
    "df_dividend = get_dividend(1301, path_save='tests/')\n",
    "# df_dividend.to_csv('tests/Data/1301/docs/dividend.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_vol_table(tables):\n",
    "    for i in range(len(tables)):\n",
    "        df = tables[i].df\n",
    "        df_find_key = df[0].str.find('期末発行済株式数（自己株式を含む）')\n",
    "        for i in df_find_key.index:\n",
    "            if df_find_key[i] >= 0:\n",
    "                id_have_key = i\n",
    "                df = df.iloc[id_have_key:, :].reset_index(drop=True)\n",
    "                return df\n",
    "\n",
    "def convert_table_mix_data(df):\n",
    "    df_add = df[3].str.split(' ', expand=True)\n",
    "    df_add2 = df[4].str.split(' ', expand=True)\n",
    "    for i in df.index:\n",
    "        if df[2][i] == '':\n",
    "            df[2][i] = df_add[0][i]\n",
    "            df[3][i] = df_add[1][i]\n",
    "        if df[5][i] == '':\n",
    "            df[5][i] = df_add2[1][i]\n",
    "            df[4][i] = df_add2[0][i]\n",
    "    return df\n",
    "     \n",
    "def drop_empty_col(df):\n",
    "    for col in df.columns:\n",
    "        if (df[col]=='').all():\n",
    "            df = df.drop(columns=col)\n",
    "    df.columns = np.arange(len(df.columns))\n",
    "    return df\n",
    "\n",
    "def get_vol_table_camelot(file_path):\n",
    "    tables = camelot.read_pdf(file_path, pages=\"all\", multiple_tables=True, flavor=\"stream\", suppress_stdout=True)\n",
    "    df = cut_vol_table(tables)\n",
    "    # print(df)\n",
    "    df = convert_table_mix_data(df)\n",
    "    df = drop_empty_col(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vol_table(file_path):\n",
    "    df = get_vol_table_tabula(file_path)\n",
    "    if df is None:\n",
    "        df = get_vol_table_camelot(file_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vol_table('tests/ocr.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[277210277, 942669]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from volume.ocr_volume import ocr_pdf\n",
    "from volume.get_volume import convert_pdf_to_text, find_row\n",
    "# ocr_pdf('tests/Data/1301/PDF/2016_Q2_決算短信(2016_11_4).pdf')\n",
    "text = convert_pdf_to_text('tests/ocr.pdf')\n",
    "lst_data_of_time = find_row(text.replace(' ', '').replace('.', ','))\n",
    "lst_data_of_time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "class FinancailStatement(setup.Setup):\n",
    "    def __init__(self):\n",
    "        super().__init__('Selenium',source=\"VS\")\n",
    "    \n",
    "    def get_data(self, link):\n",
    "        self.driver.get(link)\n",
    "        # time.sleep(5)\n",
    "        soup = BeautifulSoup(self.driver.page_source,'html.parser',from_encoding='utf-8')\n",
    "        return soup\n",
    "    \n",
    "    def get_table(self, id_company = 5486):\n",
    "        print(f\"https://www.buffett-code.com/company/{id_company}/library\")\n",
    "        soup = self.get_data(f\"https://www.buffett-code.com/company/{id_company}/library\")\n",
    "        table = soup.find_all('table')\n",
    "        return table, soup\n",
    "    \n",
    "    def get_pdf_link(self,link_):\n",
    "        self.driver.get(link_)\n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(self.driver.page_source,'html.parser',from_encoding='utf-8')\n",
    "        arr = soup.find_all('a')\n",
    "        for i in arr:\n",
    "            if i[\"href\"].find(\"pdf\") != -1:\n",
    "                return i[\"href\"]\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.buffett-code.com/company/5486/library\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = FinancailStatement()\n",
    "table = F.get_table()\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_link_df(table):\n",
    "    json_company = {}\n",
    "    for id_year, tr_year in enumerate(table[0].find_all('tr')):\n",
    "        json_company_quy = {}\n",
    "        year = ''\n",
    "        for id_quy, td_quy in enumerate(tr_year.find_all('td')):\n",
    "            lst_text, lst_link = [], []\n",
    "            for li in td_quy.find_all('li'):\n",
    "                if '決算短信' in li.text:\n",
    "                    lst_text.append(li.text)\n",
    "                    lst_link.append(f\"https://www.buffett-code.com{li.find('a')['href']}\")\n",
    "            if id_quy != 0 and id_quy != 5:\n",
    "                json_company_quy[f'Time_Q{id_quy}'] = lst_text\n",
    "                json_company_quy[f'Link_Q{id_quy}'] = lst_link\n",
    "                json_company_quy[f'Link_pdf_Q{id_quy}'] = np.nan\n",
    "            if td_quy['class'][0] == 'center':\n",
    "                year = td_quy.text\n",
    "        if year != '':\n",
    "            json_company[year] = json_company_quy.copy()\n",
    "\n",
    "    df = pd.DataFrame(json_company).T.reset_index(drop=False)\n",
    "    return df.rename(columns={'index': 'Year'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder(id_company):\n",
    "    try:\n",
    "        os.mkdir(f'{id_company}')\n",
    "        os.mkdir(f'{id_company}/PDF')\n",
    "        os.mkdir(f'{id_company}/docs')\n",
    "        os.mkdir(f'{id_company}/docx')\n",
    "        os.mkdir(f'{id_company}/volume')\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_check_point(F, id_company):\n",
    "    if not os.path.exists(f'{id_company}/docs/link.csv'):\n",
    "        table = F.get_table(id_company=id_company)\n",
    "        df = create_link_df(table)\n",
    "        df.to_csv(f'{id_company}/docs/link.csv', index=False)\n",
    "        df_check = df.copy()\n",
    "        for quy in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
    "            df_check[f'download_{quy}'] = np.nan\n",
    "        df_check.to_csv(f'{id_company}/docs/check.csv', index=False)\n",
    "    else:\n",
    "        df = pd.read_csv(f'{id_company}/docs/link.csv')\n",
    "        for quy in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
    "            df[f'Time_{quy}'] = df[f'Time_{quy}'].apply(lambda x: eval(x))\n",
    "            df[f'Link_{quy}'] = df[f'Link_{quy}'].apply(lambda x: eval(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_download_pdf(F, id_company, df):\n",
    "    df_check = pd.read_csv(f'{id_company}/docs/check.csv')\n",
    "\n",
    "    for quy in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
    "        for id in df.index:\n",
    "            if pd.isna(df_check[f'download_{quy}'][id]):\n",
    "                for id_link in range(len(df[f'Time_{quy}'][id])):\n",
    "                    year_ = df[f'Year'][id]\n",
    "                    link_preview = df[f'Link_{quy}'][id][id_link]\n",
    "                    if not 'https://www.buffett-code.com/company' in link_preview:\n",
    "                        msg = 'Nan'\n",
    "                    else:\n",
    "                        try:\n",
    "                            link_pdf = F.get_pdf_link(link_preview)\n",
    "                            name = df[f'Time_{quy}'][id][id_link].replace(' ', '').replace('/', '_')\n",
    "                            response = requests.get(link_pdf)\n",
    "                            with open(f'{id_company}/PDF/{year_}_{quy}_{name}.pdf', 'wb') as f:\n",
    "                                f.write(response.content)\n",
    "                            msg = 'OK'\n",
    "                        except:\n",
    "                            msg = None\n",
    "                    print(f'{id_company} - {year_} - {quy} - {id_link} - {msg} - {link_preview}')\n",
    "                    df_check[f'download_{quy}'][id] = msg\n",
    "                    df_check.to_csv(f'{id_company}/docs/check.csv', index=False)\n",
    "                    time.sleep(20)\n",
    "\n",
    "# get_download_pdf(F, id_company, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5486 - 2019 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/8b27f9d335f9a580017c4a/preview\n",
      "5486 - 2019 - Q4 - 1 - None - https://www.buffett-code.com/company/5486/library/c95ee4aa4b5b6a56366610/preview\n",
      "5486 - 2018 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/f19bbefaa22f0f949e4a3e/preview\n",
      "5486 - 2017 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/7feea3a7795c38520300ed/preview\n",
      "5486 - 2016 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/dfdd1bf0d33d65a0344164/preview\n",
      "5486 - 2015 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/fe38a98df616afe1548a23/preview\n",
      "5486 - 2014 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/6e8e299b89421a19185548/preview\n",
      "5486 - 2014 - Q4 - 1 - None - https://www.buffett-code.com/company/5486/library/0ada5cd2c2f35b928d8f5a/preview\n",
      "5486 - 2013 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/4951a05bc738bc116f46a0/preview\n",
      "5486 - 2012 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/615aa3ae9c5e9dae476298/preview\n",
      "5486 - 2011 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/671f4732c4f0a024a4ee74/preview\n",
      "5486 - 2010 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/b2933e09fdb813f84304c2/preview\n",
      "5486 - 2009 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/7e64ce1428f1ae20a25b34/preview\n",
      "5486 - 2008 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/e82a80f6872bda70b15fb0/preview\n"
     ]
    }
   ],
   "source": [
    "def save_pdf(id_company):\n",
    "    make_folder(id_company)\n",
    "    F = FinancailStatement()\n",
    "    df = save_check_point(F, id_company)\n",
    "    get_download_pdf(F, id_company, df)\n",
    "\n",
    "save_pdf(5486)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
