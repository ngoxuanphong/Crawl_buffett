{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\\Phong\\Crawl_buffett\n"
     ]
    }
   ],
   "source": [
    "# import tabula, camelot, os, time\n",
    "import os, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import requests\n",
    "\n",
    "# warnings.simplefilter(\"ignore\", UserWarning)\n",
    "%cd .."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get table from pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_table(df):\n",
    "    df.loc[-1] = df.columns\n",
    "    df = df.sort_index()\n",
    "    df.columns = np.arange(len(df.columns))\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def find_row(df, text):\n",
    "    list_id = np.where((df[0].str.find(text) > 0) == True)[0]\n",
    "    if len(list_id) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return list_id[0] \n",
    "    \n",
    "def get_vol_table_tabula(file_path):\n",
    "    if 'https' in file_path:\n",
    "        tables = tabula.read_pdf(file_path, pages=\"all\", multiple_tables=True, silent=True, stream=True)\n",
    "    else:\n",
    "        tables = tabula.read_pdf(file_path, pages=\"all\", multiple_tables=True, silent=True)\n",
    "    for table in range(len(tables)):\n",
    "        df = pd.DataFrame(tables[table])\n",
    "        df = convert_table(df)\n",
    "        row_id = find_row(df, \"期末発行済株式数(自己株式を含む)\")\n",
    "        if row_id is not None and len(df.columns) < 10 and len(df[0][0]) < 100:\n",
    "            return df\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_vol_table(tables):\n",
    "    for i in range(len(tables)):\n",
    "        df = tables[i].df\n",
    "        df_find_key = df[0].str.find('期末発行済株式数（自己株式を含む）')\n",
    "        for i in df_find_key.index:\n",
    "            if df_find_key[i] >= 0:\n",
    "                id_have_key = i\n",
    "                df = df.iloc[id_have_key:, :].reset_index(drop=True)\n",
    "                return df\n",
    "\n",
    "def convert_table_mix_data(df):\n",
    "    df_add = df[3].str.split(' ', expand=True)\n",
    "    df_add2 = df[4].str.split(' ', expand=True)\n",
    "    for i in df.index:\n",
    "        if df[2][i] == '':\n",
    "            df[2][i] = df_add[0][i]\n",
    "            df[3][i] = df_add[1][i]\n",
    "        if df[5][i] == '':\n",
    "            df[5][i] = df_add2[1][i]\n",
    "            df[4][i] = df_add2[0][i]\n",
    "    return df\n",
    "     \n",
    "def drop_empty_col(df):\n",
    "    for col in df.columns:\n",
    "        if (df[col]=='').all():\n",
    "            df = df.drop(columns=col)\n",
    "    df.columns = np.arange(len(df.columns))\n",
    "    return df\n",
    "\n",
    "def get_vol_table_camelot(file_path):\n",
    "    tables = camelot.read_pdf(file_path, pages=\"all\", multiple_tables=True, flavor=\"stream\", suppress_stdout=True)\n",
    "    df = cut_vol_table(tables)\n",
    "    print(df)\n",
    "    df = convert_table_mix_data(df)\n",
    "    df = drop_empty_col(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vol_table(file_path):\n",
    "    df = get_vol_table_tabula(file_path)\n",
    "    if df is None:\n",
    "        df = get_vol_table_camelot(file_path)\n",
    "    return df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "class FinancailStatement(setup.Setup):\n",
    "    def __init__(self):\n",
    "        super().__init__('Selenium',source=\"VS\")\n",
    "    \n",
    "    def get_data(self, link):\n",
    "        self.driver.get(link)\n",
    "        # time.sleep(5)\n",
    "        soup = BeautifulSoup(self.driver.page_source,'html.parser',from_encoding='utf-8')\n",
    "        return soup\n",
    "    \n",
    "    def get_table(self, id_company = 5486):\n",
    "        print(f\"https://www.buffett-code.com/company/{id_company}/library\")\n",
    "        soup = self.get_data(f\"https://www.buffett-code.com/company/{id_company}/library\")\n",
    "        table = soup.find_all('table')\n",
    "        return table\n",
    "    \n",
    "    def get_pdf_link(self,link_):\n",
    "        self.driver.get(link_)\n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(self.driver.page_source,'html.parser',from_encoding='utf-8')\n",
    "        arr = soup.find_all('a')\n",
    "        for i in arr:\n",
    "            if i[\"href\"].find(\"pdf\") != -1:\n",
    "                return i[\"href\"]\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.buffett-code.com/company/5486/library\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = FinancailStatement()\n",
    "table = F.get_table()\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_link_df(table):\n",
    "    json_company = {}\n",
    "    for id_year, tr_year in enumerate(table[0].find_all('tr')):\n",
    "        json_company_quy = {}\n",
    "        year = ''\n",
    "        for id_quy, td_quy in enumerate(tr_year.find_all('td')):\n",
    "            lst_text, lst_link = [], []\n",
    "            for li in td_quy.find_all('li'):\n",
    "                if '決算短信' in li.text:\n",
    "                    lst_text.append(li.text)\n",
    "                    lst_link.append(f\"https://www.buffett-code.com{li.find('a')['href']}\")\n",
    "            if id_quy != 0 and id_quy != 5:\n",
    "                json_company_quy[f'Time_Q{id_quy}'] = lst_text\n",
    "                json_company_quy[f'Link_Q{id_quy}'] = lst_link\n",
    "                json_company_quy[f'Link_pdf_Q{id_quy}'] = np.nan\n",
    "            if td_quy['class'][0] == 'center':\n",
    "                year = td_quy.text\n",
    "        if year != '':\n",
    "            json_company[year] = json_company_quy.copy()\n",
    "\n",
    "    df = pd.DataFrame(json_company).T.reset_index(drop=False)\n",
    "    return df.rename(columns={'index': 'Year'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder(id_company):\n",
    "    try:\n",
    "        os.mkdir(f'{id_company}')\n",
    "        os.mkdir(f'{id_company}/PDF')\n",
    "        os.mkdir(f'{id_company}/docs')\n",
    "        os.mkdir(f'{id_company}/docx')\n",
    "        os.mkdir(f'{id_company}/volume')\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_check_point(F, id_company):\n",
    "    if not os.path.exists(f'{id_company}/docs/link.csv'):\n",
    "        table = F.get_table(id_company=id_company)\n",
    "        df = create_link_df(table)\n",
    "        df.to_csv(f'{id_company}/docs/link.csv', index=False)\n",
    "        df_check = df.copy()\n",
    "        for quy in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
    "            df_check[f'download_{quy}'] = np.nan\n",
    "        df_check.to_csv(f'{id_company}/docs/check.csv', index=False)\n",
    "    else:\n",
    "        df = pd.read_csv(f'{id_company}/docs/link.csv')\n",
    "        for quy in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
    "            df[f'Time_{quy}'] = df[f'Time_{quy}'].apply(lambda x: eval(x))\n",
    "            df[f'Link_{quy}'] = df[f'Link_{quy}'].apply(lambda x: eval(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_download_pdf(F, id_company, df):\n",
    "    df_check = pd.read_csv(f'{id_company}/docs/check.csv')\n",
    "\n",
    "    for quy in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
    "        for id in df.index:\n",
    "            if pd.isna(df_check[f'download_{quy}'][id]):\n",
    "                for id_link in range(len(df[f'Time_{quy}'][id])):\n",
    "                    year_ = df[f'Year'][id]\n",
    "                    link_preview = df[f'Link_{quy}'][id][id_link]\n",
    "                    if not 'https://www.buffett-code.com/company' in link_preview:\n",
    "                        msg = 'Nan'\n",
    "                    else:\n",
    "                        try:\n",
    "                            link_pdf = F.get_pdf_link(link_preview)\n",
    "                            name = df[f'Time_{quy}'][id][id_link].replace(' ', '').replace('/', '_')\n",
    "                            response = requests.get(link_pdf)\n",
    "                            with open(f'{id_company}/PDF/{year_}_{quy}_{name}.pdf', 'wb') as f:\n",
    "                                f.write(response.content)\n",
    "                            msg = 'OK'\n",
    "                        except:\n",
    "                            msg = None\n",
    "                    print(f'{id_company} - {year_} - {quy} - {id_link} - {msg} - {link_preview}')\n",
    "                    df_check[f'download_{quy}'][id] = msg\n",
    "                    df_check.to_csv(f'{id_company}/docs/check.csv', index=False)\n",
    "                    time.sleep(20)\n",
    "\n",
    "# get_download_pdf(F, id_company, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5486 - 2019 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/8b27f9d335f9a580017c4a/preview\n",
      "5486 - 2019 - Q4 - 1 - None - https://www.buffett-code.com/company/5486/library/c95ee4aa4b5b6a56366610/preview\n",
      "5486 - 2018 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/f19bbefaa22f0f949e4a3e/preview\n",
      "5486 - 2017 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/7feea3a7795c38520300ed/preview\n",
      "5486 - 2016 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/dfdd1bf0d33d65a0344164/preview\n",
      "5486 - 2015 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/fe38a98df616afe1548a23/preview\n",
      "5486 - 2014 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/6e8e299b89421a19185548/preview\n",
      "5486 - 2014 - Q4 - 1 - None - https://www.buffett-code.com/company/5486/library/0ada5cd2c2f35b928d8f5a/preview\n",
      "5486 - 2013 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/4951a05bc738bc116f46a0/preview\n",
      "5486 - 2012 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/615aa3ae9c5e9dae476298/preview\n",
      "5486 - 2011 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/671f4732c4f0a024a4ee74/preview\n",
      "5486 - 2010 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/b2933e09fdb813f84304c2/preview\n",
      "5486 - 2009 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/7e64ce1428f1ae20a25b34/preview\n",
      "5486 - 2008 - Q4 - 0 - None - https://www.buffett-code.com/company/5486/library/e82a80f6872bda70b15fb0/preview\n"
     ]
    }
   ],
   "source": [
    "def save_pdf(id_company):\n",
    "    make_folder(id_company)\n",
    "    F = FinancailStatement()\n",
    "    df = save_check_point(F, id_company)\n",
    "    get_download_pdf(F, id_company, df)\n",
    "\n",
    "save_pdf(5486)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
