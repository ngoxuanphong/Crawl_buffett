{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\\Phong\\Crawl_buffett\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_csv('docs\\miss_irbank.csv')\n",
    "# for symbol in df['0']:\n",
    "#     shutil.rmtree(f'Data/{symbol}', ignore_errors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "df_1 = pd.read_csv('docs/May_anhNA.csv')\n",
    "df_2 = pd.read_csv('docs/may_cty.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('docs/List_company_23052023 - Listing.csv')\n",
    "# df['check'] = np.nan\n",
    "# df['volume'] = np.nan\n",
    "# df['dividend'] = np.nan\n",
    "# df['table'] = np.nan\n",
    "for id in df.index:\n",
    "    symbol = df['Symbol'][id]\n",
    "    if os.path.exists(fr'Data\\{symbol}\\docs\\link.csv'):\n",
    "        df['check'][id] = 'Done'\n",
    "        if os.path.exists(fr'Data\\{symbol}\\docs\\volume.csv'):\n",
    "            df['volume'][id] = 'Done'\n",
    "        if os.path.exists(fr'Data\\{symbol}\\docs\\dividend.csv'):\n",
    "            df['dividend'][id] = 'Done'\n",
    "        if os.path.exists(fr'Data\\{symbol}\\docs\\checklist_get_table.csv'):\n",
    "            df['table'][id] = 'Done'\n",
    "df.to_csv('docs/List_company_23052023 - Listing.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('docs\\may_cty.csv')\n",
    "# df = pd.read_csv('docs\\May_anhNA.csv')\n",
    "\n",
    "df['check'] = np.nan\n",
    "df['volume'] = np.nan\n",
    "df['dividend'] = np.nan\n",
    "df['table'] = np.nan\n",
    "for id in df.index:\n",
    "    symbol = df['Symbol'][id]\n",
    "    if os.path.exists(fr'Data\\{symbol}\\docs\\link.csv'):\n",
    "        df['check'][id] = 'Done'\n",
    "        if os.path.exists(fr'Data\\{symbol}\\docs\\volume.csv'):\n",
    "            df['volume'][id] = 'Done'\n",
    "        if os.path.exists(fr'Data\\{symbol}\\docs\\dividend.csv'):\n",
    "            df['dividend'][id] = 'Done'\n",
    "        if os.path.exists(fr'Data\\{symbol}\\docs\\checklist_get_table.csv'):\n",
    "            df['table'][id] = 'Done'\n",
    "    else:\n",
    "        df['check'][id] = np.nan\n",
    "# df.to_csv('docs\\May_anhNA.csv', index = False)\n",
    "df.to_csv('docs\\may_cty.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_miss = []\n",
    "df = pd.read_csv('docs\\may_cty.csv')\n",
    "for id in df.index:\n",
    "    symbol = df['Symbol'][id]\n",
    "    if os.path.exists(fr'Data\\{symbol}\\docs\\link.csv') and os.path.exists(fr'Data\\{symbol}\\docs\\check.csv') == False:\n",
    "        lst_miss.append(symbol)\n",
    "# df.to_csv('docs\\miss_irbank.csv', index = False)\n",
    "\n",
    "pd.DataFrame(lst_miss).to_csv('docs\\miss_irbank.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# move file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\\Phong\\Crawl_buffett\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "PATH_DRIVER = \"G:/My Drive/6_2023/Financial_1/\"\n",
    "PATH_IS = PATH_DRIVER + 'IncomeStatement/'\n",
    "PATH_BS = PATH_DRIVER + 'BalanceSheet/'\n",
    "os.makedirs(PATH_IS, exist_ok=True)\n",
    "os.makedirs(PATH_BS, exist_ok=True)\n",
    "\n",
    "symbol = 1301\n",
    "def moveFinan(symbol):\n",
    "    path_bs = rf'Data\\{symbol}\\table_bs'\n",
    "    path_pl = rf'Data\\{symbol}\\table_pl'\n",
    "    for file in os.listdir(path_bs):\n",
    "        if file.endswith('Q4.csv'):\n",
    "            os.makedirs(PATH_BS + '/' + str(symbol), exist_ok=True)\n",
    "            shutil.copy(path_bs + '/' + file, PATH_BS + '/' + str(symbol) + '/' + file)\n",
    "    for file in os.listdir(path_pl):\n",
    "        if file.endswith('Q4.csv'):\n",
    "            os.makedirs(PATH_IS + str(symbol), exist_ok=True)\n",
    "            shutil.copy(path_pl + '/' + file, PATH_IS + '/' + str(symbol) + '/' + file)\n",
    "\n",
    "df = pd.read_csv('docs\\List_company_23052023 - Listing.csv')\n",
    "for id in df.index:\n",
    "    symbol = df['Symbol'][id]\n",
    "    if df['check'][id] == 'Done':\n",
    "        try:\n",
    "            moveFinan(symbol)\n",
    "        except Exception as e:\n",
    "            print(symbol, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_DRIVER = \"H:/My Drive/6_2023/Done_Japan1\"\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "PATH_DRIVER = \"I:/My Drive/6_2023/DoneJapan\"\n",
    "os.makedirs(rf'{PATH_DRIVER}/dividend', exist_ok=True)\n",
    "\n",
    "def sortDate(df, type_ = 'volume'):\n",
    "    if type_ == 'volume':\n",
    "        df['Time'] = pd.to_datetime(df['Time'], format='%Y_%m_%d', errors='coerce')\n",
    "    else:\n",
    "        df['Time'] = pd.to_datetime(df['Time'], format='%d_%m_%Y', errors='coerce')\n",
    "    df.sort_values(by=['Time'], inplace=True)\n",
    "    df['Time'] = df['Time'].dt.strftime('%d/%m/%Y')\n",
    "    return df\n",
    "\n",
    "def delDate(time, date):\n",
    "    if pd.isna(date):\n",
    "        return date\n",
    "    if 'Q1' in time or 'Q2' in time:\n",
    "        date = pd.to_datetime(date, format='%Y_%m_%d', errors='coerce')\n",
    "        date = date - timedelta(days=365)\n",
    "        date = date.strftime('%Y_%m_%d')\n",
    "    return date\n",
    "\n",
    "def getVolume(symbol, PATH = rf'{PATH_DRIVER}/volume/'):\n",
    "    df = pd.read_csv(fr'Data\\{symbol}\\docs\\volume.csv')\n",
    "    if not os.path.exists(fr'Data\\{symbol}\\docs\\check.csv'):\n",
    "        df['date'] = df[['time', 'date']].apply(lambda x: delDate(x['time'], x['date']), axis=1)\n",
    "    df['volume'] = df['vol1'] - df['vol2']\n",
    "    df = df[['date', 'volume']]\n",
    "    df.dropna(how = 'all', inplace=True)\n",
    "    df.rename(columns={'date': 'Time', 'volume': 'Volume'}, inplace=True)\n",
    "    df = sortDate(df, type_ = 'volume')\n",
    "    df.to_csv(fr'{PATH}{symbol}.csv', index = False)\n",
    "    return df\n",
    "\n",
    "def getDividend(symbol, PATH = rf'{PATH_DRIVER}/dividend/'):\n",
    "    df = pd.read_csv(fr'Data\\{symbol}\\docs\\dividend.csv')\n",
    "    df_done = pd.DataFrame(columns = ['Time', 'Stock', 'Money', 'Time2'])\n",
    "    df_done['Time'] = df[['time_split_Q1', 'time_split_Q2', 'time_split_Q3', 'time_split_Q4']].stack(dropna=False).reset_index(drop=True)\n",
    "    df_done['Time'] = df_done['Time'].str.replace(\"['\", '').str.replace(\"']\", '')\n",
    "    df_done['Money'] = df[['Q1', 'Q2', 'Q3', 'Q4']].stack(dropna=False).reset_index(drop=True)\n",
    "    for q in  ['Q1', 'Q2', 'Q3', 'Q4']:\n",
    "        df[q] = df['Year'].astype(str) + '_' + q\n",
    "    df_done['Time2'] = df[['Q1', 'Q2', 'Q3', 'Q4']].stack(dropna=False).reset_index(drop=True)\n",
    "    df_done.replace('－', np.nan, inplace=True)\n",
    "    df_done.replace('―', np.nan, inplace=True)\n",
    "    df_done.replace('-', np.nan, inplace=True)\n",
    "    df_done.replace('—', np.nan, inplace=True)\n",
    "    df_done.replace('一', np.nan, inplace=True)\n",
    "    df_done.replace('=', np.nan, inplace=True)\n",
    "    df_done.dropna(inplace=True, thresh=2)\n",
    "    df_done = sortDate(df_done, type_ = 'dividend')\n",
    "    df_done.to_csv(fr'{PATH}{symbol}.csv', index = False)\n",
    "    return df_done\n",
    "\n",
    "symbol = 2190\n",
    "getVolume(symbol)\n",
    "getDividend(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('docs\\List_company_23052023 - Listing.csv')\n",
    "for id in df.index:\n",
    "    symbol = df['Symbol'][id]\n",
    "    if df['check'][id] == 'Done':\n",
    "        if os.path.exists(fr'Data\\{symbol}\\docs\\volume.csv'):\n",
    "            try:\n",
    "                getVolume(symbol)\n",
    "            except Exception as e:\n",
    "                print(symbol, e)\n",
    "                break\n",
    "\n",
    "        if os.path.exists(fr'Data\\{symbol}\\docs\\dividend.csv'):\n",
    "            try:\n",
    "                getDividend(symbol)\n",
    "            except Exception as e:\n",
    "                print(symbol, e)\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\\Phong\\Crawl_buffett\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from src.volume import GetVolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = GetVolume(path_save='')\n",
    "# vol.getDataFromPdf(id_company=1333, year = 2015, quy = 'Q1')\n",
    "vol.getVolume(8333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>vol1</th>\n",
       "      <th>vol2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_Q1</td>\n",
       "      <td>2015_08_05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014_Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_Q2</td>\n",
       "      <td>2015_11_06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014_Q2</td>\n",
       "      <td>2014_11_08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_Q3</td>\n",
       "      <td>2015_02_05</td>\n",
       "      <td>4171300.0</td>\n",
       "      <td>385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014_Q3</td>\n",
       "      <td>2014_02_07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015_Q4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014_Q4</td>\n",
       "      <td>2014_05_08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      time        date       vol1   vol2\n",
       "0  2015_Q1  2015_08_05        NaN    NaN\n",
       "1  2014_Q1         NaN        NaN    NaN\n",
       "2  2015_Q2  2015_11_06        NaN    NaN\n",
       "3  2014_Q2  2014_11_08        NaN    NaN\n",
       "4  2015_Q3  2015_02_05  4171300.0  385.0\n",
       "5  2014_Q3  2014_02_07        NaN    NaN\n",
       "6  2015_Q4         NaN        NaN    NaN\n",
       "7  2014_Q4  2014_05_08        NaN    NaN"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol = 2190\n",
    "path_volume = fr'Data\\{symbol}\\docs\\volume.csv'\n",
    "path_link = fr'Data\\{symbol}\\docs\\link.csv'\n",
    "path1 = fr'Data\\{symbol}\\PDF'\n",
    "df = pd.read_csv(path_volume)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# df.apply(lambda x: delDate(x['time'], x['date']), axis=1)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[[\u001b[39m'\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m]] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: delDate(x[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m], x[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m df\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3948\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3946\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_frame(key, value)\n\u001b[0;32m   3947\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, (Series, np\u001b[39m.\u001b[39mndarray, \u001b[39mlist\u001b[39m, Index)):\n\u001b[1;32m-> 3948\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_array(key, value)\n\u001b[0;32m   3949\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m   3950\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_item_frame_value(key, value)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4007\u001b[0m, in \u001b[0;36mDataFrame._setitem_array\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4004\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array(key, value)\n\u001b[0;32m   4006\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4007\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iset_not_inplace(key, value)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4026\u001b[0m, in \u001b[0;36mDataFrame._iset_not_inplace\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4024\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique:\n\u001b[0;32m   4025\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mshape(value)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(key):\n\u001b[1;32m-> 4026\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mColumns must be same length as key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   4028\u001b[0m     \u001b[39mfor\u001b[39;00m i, col \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(key):\n\u001b[0;32m   4029\u001b[0m         \u001b[39mself\u001b[39m[col] \u001b[39m=\u001b[39m igetitem(value, i)\n",
      "\u001b[1;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "# df.apply(lambda x: delDate(x['time'], x['date']), axis=1)\n",
    "df[['date']] = df.apply(lambda x: delDate(x['time'], x['date']), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "EncryptedPdfError",
     "evalue": "Input PDF is encrypted. The encryption must be removed to\nperform OCR.\n\nFor information about this PDF's security use\n    qpdf --show-encryption infilename\n\nYou can remove the encryption using\n    qpdf --decrypt [--password=[password]] infilename\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEncryptedPdfError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mocrPdf\u001b[39;00m \u001b[39mimport\u001b[39;00m ocrPDF\n\u001b[1;32m----> 3\u001b[0m ocrPDF(\u001b[39mfr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mA:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mPhong\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mCrawl_buffett\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mData\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39m5289\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mPDF\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39m2017_Q1_(2017_08_10).pdf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mhi.pdf\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32ma:\\Phong\\Crawl_buffett\\src\\ocrPdf.py:53\u001b[0m, in \u001b[0;36mocrPDF\u001b[1;34m(input_file, output_file)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mocrPDF\u001b[39m(input_file, output_file \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> 53\u001b[0m     timeout_function(ocrPDF_(input_file, output_file), \u001b[39m20\u001b[39m)\n",
      "File \u001b[1;32ma:\\Phong\\Crawl_buffett\\src\\ocrPdf.py:39\u001b[0m, in \u001b[0;36mocrPDF_\u001b[1;34m(input_file, output_file)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mif\u001b[39;00m output_file \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     output_file \u001b[39m=\u001b[39m input_file\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.pdf\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_ocr.pdf\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m ocrmypdf\u001b[39m.\u001b[39;49mocr(\n\u001b[0;32m     40\u001b[0m     input_file,\n\u001b[0;32m     41\u001b[0m     output_file,\n\u001b[0;32m     42\u001b[0m     language\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39meng+jpn\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     43\u001b[0m     force_ocr\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     44\u001b[0m     output_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpdf\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     45\u001b[0m     optimize\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m     46\u001b[0m     progress_bar\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     47\u001b[0m     \u001b[39m# skip_big = True,\u001b[39;49;00m\n\u001b[0;32m     48\u001b[0m     max_image_mpixels\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     50\u001b[0m \u001b[39mreturn\u001b[39;00m output_file\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ocrmypdf\\api.py:346\u001b[0m, in \u001b[0;36mocr\u001b[1;34m(input_file, output_file, language, image_dpi, output_type, sidecar, jobs, use_threads, title, author, subject, keywords, rotate_pages, remove_background, deskew, clean, clean_final, unpaper_args, oversample, remove_vectors, force_ocr, skip_text, redo_ocr, skip_big, optimize, jpg_quality, png_quality, jbig2_lossy, jbig2_page_group_size, pages, max_image_mpixels, tesseract_config, tesseract_pagesegmode, tesseract_oem, tesseract_thresholding, pdf_renderer, tesseract_timeout, tesseract_non_ocr_timeout, rotate_pages_threshold, pdfa_image_compression, user_words, user_patterns, fast_web_view, plugins, plugin_manager, keep_temporary_files, progress_bar, **kwargs)\u001b[0m\n\u001b[0;32m    344\u001b[0m options \u001b[39m=\u001b[39m create_options(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcreate_options_kwargs)\n\u001b[0;32m    345\u001b[0m check_options(options, plugin_manager)\n\u001b[1;32m--> 346\u001b[0m \u001b[39mreturn\u001b[39;00m run_pipeline(options\u001b[39m=\u001b[39;49moptions, plugin_manager\u001b[39m=\u001b[39;49mplugin_manager, api\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ocrmypdf\\_sync.py:376\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[1;34m(options, plugin_manager, api)\u001b[0m\n\u001b[0;32m    371\u001b[0m origin_pdf \u001b[39m=\u001b[39m triage(\n\u001b[0;32m    372\u001b[0m     original_filename, start_input_file, work_folder \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39morigin.pdf\u001b[39m\u001b[39m'\u001b[39m, options\n\u001b[0;32m    373\u001b[0m )\n\u001b[0;32m    375\u001b[0m \u001b[39m# Gather pdfinfo and create context\u001b[39;00m\n\u001b[1;32m--> 376\u001b[0m pdfinfo \u001b[39m=\u001b[39m get_pdfinfo(\n\u001b[0;32m    377\u001b[0m     origin_pdf,\n\u001b[0;32m    378\u001b[0m     executor\u001b[39m=\u001b[39;49mexecutor,\n\u001b[0;32m    379\u001b[0m     detailed_analysis\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49mredo_ocr,\n\u001b[0;32m    380\u001b[0m     progbar\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49mprogress_bar,\n\u001b[0;32m    381\u001b[0m     max_workers\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49mjobs \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m options\u001b[39m.\u001b[39;49muse_threads \u001b[39melse\u001b[39;49;00m \u001b[39m1\u001b[39;49m,  \u001b[39m# To help debug\u001b[39;49;00m\n\u001b[0;32m    382\u001b[0m     check_pages\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49mpages,\n\u001b[0;32m    383\u001b[0m )\n\u001b[0;32m    385\u001b[0m context \u001b[39m=\u001b[39m PdfContext(options, work_folder, origin_pdf, pdfinfo, plugin_manager)\n\u001b[0;32m    387\u001b[0m \u001b[39m# Validate options are okay for this pdf\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ocrmypdf\\_pipeline.py:164\u001b[0m, in \u001b[0;36mget_pdfinfo\u001b[1;34m(input_file, executor, detailed_analysis, progbar, max_workers, check_pages)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_pdfinfo\u001b[39m(\n\u001b[0;32m    155\u001b[0m     input_file,\n\u001b[0;32m    156\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m     check_pages\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    162\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PdfInfo:\n\u001b[0;32m    163\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 164\u001b[0m         \u001b[39mreturn\u001b[39;00m PdfInfo(\n\u001b[0;32m    165\u001b[0m             input_file,\n\u001b[0;32m    166\u001b[0m             detailed_analysis\u001b[39m=\u001b[39;49mdetailed_analysis,\n\u001b[0;32m    167\u001b[0m             progbar\u001b[39m=\u001b[39;49mprogbar,\n\u001b[0;32m    168\u001b[0m             max_workers\u001b[39m=\u001b[39;49mmax_workers,\n\u001b[0;32m    169\u001b[0m             check_pages\u001b[39m=\u001b[39;49mcheck_pages,\n\u001b[0;32m    170\u001b[0m             executor\u001b[39m=\u001b[39;49mexecutor,\n\u001b[0;32m    171\u001b[0m         )\n\u001b[0;32m    172\u001b[0m     \u001b[39mexcept\u001b[39;00m pikepdf\u001b[39m.\u001b[39mPasswordError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    173\u001b[0m         \u001b[39mraise\u001b[39;00m EncryptedPdfError() \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ocrmypdf\\pdfinfo\\info.py:973\u001b[0m, in \u001b[0;36mPdfInfo.__init__\u001b[1;34m(self, infile, detailed_analysis, progbar, max_workers, check_pages, executor)\u001b[0m\n\u001b[0;32m    971\u001b[0m \u001b[39mwith\u001b[39;00m Pdf\u001b[39m.\u001b[39mopen(infile) \u001b[39mas\u001b[39;00m pdf:\n\u001b[0;32m    972\u001b[0m     \u001b[39mif\u001b[39;00m pdf\u001b[39m.\u001b[39mis_encrypted:\n\u001b[1;32m--> 973\u001b[0m         \u001b[39mraise\u001b[39;00m EncryptedPdfError()  \u001b[39m# Triggered by encryption with empty passwd\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pages \u001b[39m=\u001b[39m _pdf_pageinfo_concurrent(\n\u001b[0;32m    975\u001b[0m         pdf,\n\u001b[0;32m    976\u001b[0m         executor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    981\u001b[0m         detailed_analysis\u001b[39m=\u001b[39mdetailed_analysis,\n\u001b[0;32m    982\u001b[0m     )\n\u001b[0;32m    983\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_needs_rendering \u001b[39m=\u001b[39m pdf\u001b[39m.\u001b[39mRoot\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39m/NeedsRendering\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mEncryptedPdfError\u001b[0m: Input PDF is encrypted. The encryption must be removed to\nperform OCR.\n\nFor information about this PDF's security use\n    qpdf --show-encryption infilename\n\nYou can remove the encryption using\n    qpdf --decrypt [--password=[password]] infilename\n"
     ]
    }
   ],
   "source": [
    "from src.ocrPdf import ocrPDF\n",
    "\n",
    "ocrPDF(fr\"A:\\Phong\\Crawl_buffett\\Data\\5289\\PDF\\2017_Q1_(2017_08_10).pdf\", 'hi.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
