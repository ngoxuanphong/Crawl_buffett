{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula, camelot, os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_table(df):\n",
    "    df.loc[-1] = df.columns\n",
    "    df = df.sort_index()\n",
    "    df.columns = np.arange(len(df.columns))\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def find_row(df, text):\n",
    "    list_id = np.where((df[0].str.find(text) > 0) == True)[0]\n",
    "    if len(list_id) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return list_id[0] \n",
    "    \n",
    "def get_vol_table_tabula(file_path):\n",
    "    if 'https' in file_path:\n",
    "        tables = tabula.read_pdf(file_path, pages=\"all\", multiple_tables=True, silent=True, stream=True)\n",
    "    else:\n",
    "        tables = tabula.read_pdf(file_path, pages=\"all\", multiple_tables=True, silent=True)\n",
    "    for table in range(len(tables)):\n",
    "        df = pd.DataFrame(tables[table])\n",
    "        df = convert_table(df)\n",
    "        row_id = find_row(df, \"期末発行済株式数(自己株式を含む)\")\n",
    "        if row_id is not None and len(df.columns) < 10 and len(df[0][0]) < 100:\n",
    "            return df\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_vol_table(tables):\n",
    "    for i in range(len(tables)):\n",
    "        df = tables[i].df\n",
    "        df_find_key = df[0].str.find('期末発行済株式数（自己株式を含む）')\n",
    "        for i in df_find_key.index:\n",
    "            if df_find_key[i] >= 0:\n",
    "                id_have_key = i\n",
    "                df = df.iloc[id_have_key:, :].reset_index(drop=True)\n",
    "                return df\n",
    "\n",
    "def convert_table_mix_data(df):\n",
    "    df_add = df[3].str.split(' ', expand=True)\n",
    "    df_add2 = df[4].str.split(' ', expand=True)\n",
    "    for i in df.index:\n",
    "        if df[2][i] == '':\n",
    "            df[2][i] = df_add[0][i]\n",
    "            df[3][i] = df_add[1][i]\n",
    "        if df[5][i] == '':\n",
    "            df[5][i] = df_add2[1][i]\n",
    "            df[4][i] = df_add2[0][i]\n",
    "    return df\n",
    "     \n",
    "def drop_empty_col(df):\n",
    "    for col in df.columns:\n",
    "        if (df[col]=='').all():\n",
    "            df = df.drop(columns=col)\n",
    "    df.columns = np.arange(len(df.columns))\n",
    "    return df\n",
    "\n",
    "def get_vol_table_camelot(file_path):\n",
    "    tables = camelot.read_pdf(file_path, pages=\"all\", multiple_tables=True, flavor=\"stream\", suppress_stdout=True)\n",
    "    df = cut_vol_table(tables)\n",
    "    df = convert_table_mix_data(df)\n",
    "    df = drop_empty_col(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vol_table(file_path):\n",
    "    df = get_vol_table_tabula(file_path)\n",
    "    if df is None:\n",
    "        df = get_vol_table_camelot(file_path)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\__init__.py:203: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n"
     ]
    }
   ],
   "source": [
    "import setup\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "class FinancailStatement(setup.Setup):\n",
    "    def __init__(self):\n",
    "        super().__init__('Selenium',source=\"VS\")\n",
    "        # self.link = \"https://www.buffett-code.com/company/5486/library\"\n",
    "    \n",
    "    def get_data(self, link):\n",
    "        self.driver.get(link)\n",
    "        time.sleep(5)\n",
    "        soup = BeautifulSoup(self.driver.page_source,'html.parser',from_encoding='utf-8')\n",
    "        # self.driver.close()\n",
    "        # self.driver.quit()\n",
    "        return soup\n",
    "    \n",
    "    def get_table(self,soup = \"\", id_company = 5486):\n",
    "        if soup == \"\":\n",
    "            soup = self.get_data(f\"https://www.buffett-code.com/company/{id_company}/library\")\n",
    "        else:\n",
    "            soup = BeautifulSoup(soup,'html.parser',from_encoding='utf-8')\n",
    "        table = soup.find_all('table')\n",
    "        return table\n",
    "    \n",
    "    def get_pdf_link(self,link_):\n",
    "        self.driver.get(link_)\n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(self.driver.page_source,'html.parser',from_encoding='utf-8')\n",
    "        arr = soup.find_all('a')\n",
    "        for i in arr:\n",
    "            if i[\"href\"].find(\"pdf\") != -1:\n",
    "                return i[\"href\"]\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_link_df(table):\n",
    "    json_company = {}\n",
    "    for id_year, tr_year in enumerate(table[0].find_all('tr')):\n",
    "        json_company_quy = {}\n",
    "        year = ''\n",
    "        for id_quy, td_quy in enumerate(tr_year.find_all('td')):\n",
    "            lst_text, lst_link = [], []\n",
    "            for li in td_quy.find_all('li'):\n",
    "                if '決算短信' in li.text:\n",
    "                    lst_text.append(li.text)\n",
    "                    lst_link.append(f\"https://www.buffett-code.com{li.find('a')['href']}\")\n",
    "            if id_quy != 0 and id_quy != 5:\n",
    "                json_company_quy[f'Time_Q{id_quy}'] = lst_text\n",
    "                json_company_quy[f'Link_Q{id_quy}'] = lst_link\n",
    "            if td_quy['class'][0] == 'center':\n",
    "                year = td_quy.text\n",
    "        if year != '':\n",
    "            json_company[year] = json_company_quy.copy()\n",
    "    return pd.DataFrame(json_company).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(F, df, id_company, df_check):\n",
    "    for quy in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
    "        for year in df.index:\n",
    "            for id_link in range(len(df[f'Time_{quy}'][year])):\n",
    "                link_preview = df[f'Link_{quy}'][year][id_link]\n",
    "                link_pdf = F.get_pdf_link(link_preview)\n",
    "                name = df[f'Time_{quy}'][year][id_link]\n",
    "                if link_preview != 'https://www.buffett-code.com#':\n",
    "                    print(year, quy, link_pdf)\n",
    "                    try:\n",
    "                        df_vol = get_vol_table(link_pdf)\n",
    "                        df_vol.to_csv(f'{id_company}/{year}_{quy}.csv', index=False)\n",
    "                        df_check[f'Link_{quy}'][year][id_link] = 'Done'\n",
    "                    except:\n",
    "                        df_check[f'Link_{quy}'][year][id_link] = 'Error'\n",
    "                    df_check.to_csv(f'{id_company}/docs/checklist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vol_buffett(id_company):\n",
    "    if not os.path.exists(f'{id_company}'):\n",
    "        os.mkdir(f'{id_company}')\n",
    "    if not os.path.exists(f'{id_company}/docs'):\n",
    "        os.mkdir(f'{id_company}/docs')\n",
    "\n",
    "    F = FinancailStatement()\n",
    "    table = F.get_table(id_company = id_company)\n",
    "    df = create_link_df(table)\n",
    "\n",
    "    df_check = df.copy()\n",
    "    df.to_csv(f'{id_company}/link.csv')\n",
    "    df_check.to_csv(f'{id_company}/docs/checklist.csv')\n",
    "\n",
    "    save_csv(F, df, id_company, df_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vol_buffett(5468)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
